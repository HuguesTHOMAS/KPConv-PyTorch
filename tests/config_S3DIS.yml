colors:
  header: \033[95m
  okblue: \033[94m
  okgreen: \033[92m
  warning: \033[93m
  fail: \033[91m
  endc: \033[0m
  bold: \033[1m
  underline: \033[4m

# Name of the dataset, possible values: S3DIS, ModelNet40, SemanticKitti, Toronto3D, NPM3D
dataset: S3DIS

input:
  # Type of network model, possible values: classification, segmentation, cloud_segmentation for S3DIS, slam_segmentation
  task: cloud_segmentation
  # Choice of input features
  features_dim: 5
  # Dimension of input points
  points_dim: 3
  # Number of CPU threads for the input pipeline
  threads: 10
  # Radius of the input sphere (decrease value to reduce memory cost)
  sphere_radius: 1.2
  # Using potential or random epoch generation
  use_potentials: True

model:
  architecture:
    - simple
    - resnetb
    - resnetb_strided
    - resnetb
    - resnetb
    - resnetb_strided
    - resnetb
    - resnetb
    - resnetb_strided
    - resnetb_deformable
    - resnetb_deformable
    - resnetb_deformable_strided
    - resnetb_deformable
    - resnetb_deformable
    - nearest_upsample
    - unary
    - nearest_upsample
    - unary
    - nearest_upsample
    - unary
    - nearest_upsample
    - unary
  batch_norm_momentum: 0.02
  # Decide the mode of equivariance
  equivar_mode:
  # Dimension of the first feature maps
  first_features_dim: 128
  # Decide the mode of invariance
  invar_mode:
  num_layers:
  # Dict from labels to names
  label_to_names:
    0: ceiling
    1: floor
    2: wall
    3: beam
    4: column
    5: window
    6: door
    7: chair
    8: table
    9: bookcase
    10: sofa
    11: board
    12: clutter
  # Do we need to save convergence
  saving: True
  # For segmentation models: ratio between the segmented area and the input area
  segmentation_ratio:
  # Batch normalization parameters
  use_batch_norm: True

kpconv:
  # Aggregation function of KPConv in ('closest', 'sum')
  # Decide if you sum all kernel point influences,
  # or if you only take the influence of the closest KP
  aggregation_mode: sum
  # Radius of convolution in number grid cell. (2.5 is the standard value)
  conv_radius: 2.5
  # Deformable offset loss
  # Fitting geometry by penalizing distance from deform point to input points ('point2point')
  # or to input point triplet ('point2plane', not implemented)
  deform_fitting_mode: "point2point"
  # Multiplier for the fitting/repulsive loss
  deform_fitting_power: 1.0
  # Radius of deformable convolution in number grid cell. Larger so that deformed kernel can spread out
  deform_radius: 5.0
  # Size of the first subsampling grid in meters
  first_subsampling_dl: 0.03
  # Fixed points in the kernel : 'none', 'center' or 'verticals'
  fixed_kernel_points: none
  # Radius of the area of influence of each kernel point in number grid cell. (1.0 is the standard value)
  KP_extent: 1.0
  # Behaviour of convolutions. Influence function when d < KP_extent. ('constant', 'linear', 'gaussian')
  # When d > KP_extent, always zero
  KP_influence: linear
  max_in_points:
  # Radius of the area of influence of each kernel point in number grid cell. (1.0 is the standard value)
  max_val_points: 50000
  # Can the network learn modulations (in deformable convolutions)
  modulated: False
  n_frames: 1
  # Number of kernel points
  num_kernel_points: 15
  val_radius:

train:
  # Augmentations
  augment_color: 0.8
  augment_noise: 0.001
  augment_occlusion: none
  augment_occlusion_ratio: 0.2
  augment_occlusion_num: 1
  augment_rotation: vertical
  augment_scale_anisotropic: True
  augment_scale_min: 0.9
  augment_scale_max: 1.1
  augment_symmetries: [True, False, False]
  # Number of batch (decrease to reduce memory cost, but it should remain > 3 for stability)
  batch_num: 6
  # Frequency at which training checkpoints are saved on disk (in terms of epochs)
  checkpoint_gap: 1
  # Deformable offset loss
  # Fitting geometry by penalizing distance from deform point to input points ('point2point')
  # or to input point triplet ('point2plane', not implemented)
  # Choose weights for class (used in segmentation loss). Empty list for no weights
  class_w: {}
  # Multiplier for learning rate applied to the deformations
  deform_lr_factor: 0.1
  # Number of steps per epochs
  epoch_steps: 3
  # Gradient clipping value (negative means no clipping)
  grad_clip_norm: 100.0
  # Learning rate management
  learning_rate: 0.01
  lr_decay_epochs:
  # Maximal number of epochs
  max_epoch: 1
  momentum: 0.98
  # Increment of inference potential before saving results
  potential_increment: 4
  # Distance of repulsion for deformed kernel points
  repulse_extent: 1.2
  # The way we balance segmentation loss
  # - 'none': Each point in the whole batch has the same contribution.
  # - 'class': Each class has the same contribution (points are weighted according to class balance)
  # - 'batch': Each cloud in the batch has the same contribution (points are weighted according cloud sizes)
  segloss_balance: none
  train_folder: original_ply
  train_cloud_names:
    - Area_1
    - Area_2
    - Area_3
    - Area_4
    - Area_6
  validation_cloud_names:
    - Area_5
  # Number of validation examples per epoch
  validation_size: 5
  # Regularization loss importance
  weight_decay: 0.001

test:
  # Increment of inference potential before saving results
  potential_increment: 2
  n_votes: 1
  val_bath_num: 10
  # Number of validation examples per epoch
  validation_size: 5
