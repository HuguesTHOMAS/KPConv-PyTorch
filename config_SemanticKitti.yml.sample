colors:
  header: \033[95m
  okblue: \033[94m
  okgreen: \033[92m
  warning: \033[93m
  fail: \033[91m
  endc: \033[0m
  bold: \033[1m
  underline: \033[4m

# Name of the dataset, possible values: S3DIS, ModelNet40, SemanticKitti, Toronto3D, NPM3D
dataset: SemanticKitti

input:
  # Type of network model, possible values: classification, segmentation, cloud_segmentation for S3DIS, slam_segmentation
  dataset_task: "slam_segmentation"
  # Aggregation function of KPConv in ('closest', 'sum')
  # Decide if you sum all kernel point influences,
  # or if you only take the influence of the closest KP
  aggregation_mode: "sum"
  # Choice of input features
  in_features_dim: 2
  # Dimension of input points
  in_points_dim: 3
  # Number of CPU threads for the input pipeline
  input_threads: 10
  # Radius of the input sphere (decrease value to reduce memory cost)
  in_radius: 4.0
  # Number of classes in the dataset
  num_classes: 0
  # Using potential or random epoch generation
  use_potentials: True

model:
  architecture:
    - "simple"
    - "resnetb"
    - "resnetb_strided"
    - "resnetb"
    - "resnetb"
    - "resnetb_strided"
    - "resnetb"
    - "resnetb"
    - "resnetb_strided"
    - "resnetb"
    - "resnetb"
    - "resnetb_strided"
    - "resnetb"
    - "nearest_upsample"
    - "unary"
    - "nearest_upsample"
    - "unary"
    - "nearest_upsample"
    - "unary"
    - "nearest_upsample"
    - "unary"
  batch_norm_momentum: 0.02
  # Dimension of the first feature maps
  first_features_dim: 128
  num_layers:
  # Do we need to save convergence
  saving: True
  # Batch normalization parameters
  use_batch_norm: True

kpconv:
  # Aggregation function of KPConv in ('closest', 'sum')
  # Decide if you sum all kernel point influences,
  # or if you only take the influence of the closest KP
  aggregation_mode: "sum"
  # Radius of convolution in "number grid cell". (2.5 is the standard value)
  conv_radius: 2.5
  # Deformable offset loss
  # Fitting geometry by penalizing distance from deform point to input points ('point2point')
  # or to input point triplet ('point2plane', not implemented)
  deform_fitting_mode: "point2point"
  # Multiplier for the fitting/repulsive loss
  deform_fitting_power: 1.0
  # Multiplier for learning rate applied to the deformations
  deform_lr_factor: 0.1
  # Radius of deformable convolution in "number grid cell". Larger so that deformed kernel can spread out
  deform_radius: 6.0
  # Size of the first subsampling grid in meters
  first_subsampling_dl: 0.06
  # Fixed points in the kernel : 'none', 'center' or 'verticals'
  fixed_kernel_points: "none"
  # Radius of the area of influence of each kernel point in "number grid cell". (1.0 is the standard value)
  KP_extent: 1.2
  # Behaviour of convolutions. Influence function when d < KP_extent. ('constant', 'linear', 'gaussian')
  # When d > KP_extent, always zero
  KP_influence: "linear"
  # Maximal number of epochs
  max_epoch: 800
  max_in_points: 100000
  # Radius of the area of influence of each kernel point in "number grid cell". (1.0 is the standard value)
  max_val_points: 100000
  # Can the network learn modulations (in deformable convolutions)
  modulated: False
  n_frames: 1
  num_kernel_points: 15
  val_radius: 51.0

train:
  # Augmentation parameters
  augment_color: 0.8
  augment_noise: 0.001
  augment_occlusion: "none"
  augment_occlusion_ratio: 0.2
  augment_occlusion_num: 1
  augment_rotation: "vertical"
  augment_scale_anisotropic: True
  augment_scale_min: 0.8
  augment_scale_max: 1.2
  augment_symmetries: [True, False, False]
  # Number of batch
  batch_num: 10
  # Number of epoch between each checkpoint
  checkpoint_gap: 50
  # Deformable offset loss
  # Fitting geometry by penalizing distance from deform point to input points ('point2point')
  # or to input point triplet ('point2plane', not implemented)
  # Choose weights for class (used in segmentation loss). Empty list for no weights
  # class proportion for R=10.0 and dl=0.08 (first is unlabeled)
  # 19.1 48.9 0.5 1.1 5.6 3.6 0.7 0.6 0.9 193.2 17.7 127.4 6.7 132.3 68.4 283.8 7.0 78.5 3.3 0.8
  # sqrt(Inverse of proportion * 100)
  # class_w = [1.430, 14.142, 9.535, 4.226, 5.270, 11.952, 12.910, 10.541, 0.719,
  #            2.377, 0.886, 3.863, 0.869, 1.209, 0.594, 3.780, 1.129, 5.505, 11.180]
  # sqrt(Inverse of proportion * 100)  capped (0.5 < X < 5)
  # class_w = [1.430, 5.000, 5.000, 4.226, 5.000, 5.000, 5.000, 5.000, 0.719, 2.377,
  #            0.886, 3.863, 0.869, 1.209, 0.594, 3.780, 1.129, 5.000, 5.000]
  class_w: []
  # Multiplier for learning rate applied to the deformations
  deform_lr_factor: 0.1
  # Number of steps per epochs
  epoch_steps: 500
  # Gradient clipping value (negative means no clipping)
  grad_clip_norm: 100.0
  # Network optimizer parameters (learning rate and momentum)
  learning_rate: 1e-2
  momentum: 0.98
  # Increment of inference potential before saving results
  potential_increment: 10
  # Distance of repulsion for deformed kernel points
  repulse_extent: 1.0
  # The way we balance segmentation loss
  # - 'none': Each point in the whole batch has the same contribution.
  # - 'class': Each class has the same contribution (points are weighted according to class balance)
  # - 'batch': Each cloud in the batch has the same contribution (points are weighted according cloud sizes)
  segloss_balance: "none"
  val_batch_num: 8
  # Number of validation examples per epoch
  validation_size: 200
  # Regularization loss importance
  weight_decay: 1e-3

test:
  # Number of CPU threads for the input pipeline
  input_threads: 10
  # Number of validation examples per epoch
  validation_size: 200
