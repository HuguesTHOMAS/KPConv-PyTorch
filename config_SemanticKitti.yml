# Name of the dataset, possible values: S3DIS, ModelNet40, SemanticKitti, Toronto3D, NPM3D
dataset: SemanticKitti

input:
  # Type of network model, possible values: classification, segmentation, cloud_segmentation for S3DIS, slam_segmentation
  task: slam_segmentation
  # Aggregation function of KPConv in ('closest', 'sum')
  # Decide if you sum all kernel point influences,
  # or if you only take the influence of the closest KP
  aggregation_mode: sum
  # Choice of input features
  features_dim: 2
  # Dimension of input points
  points_dim: 3
  # Number of CPU threads for the input pipeline
  threads: 10
  # Radius of the input sphere (decrease value to reduce memory cost)
  sphere_radius: 4.0
  # Using potential or random epoch generation
  use_potentials: True

model:
  architecture:
    - simple
    - resnetb
    - resnetb_strided
    - resnetb
    - resnetb
    - resnetb_strided
    - resnetb
    - resnetb
    - resnetb_strided
    - resnetb
    - resnetb
    - resnetb_strided
    - resnetb
    - nearest_upsample
    - unary
    - nearest_upsample
    - unary
    - nearest_upsample
    - unary
    - nearest_upsample
    - unary
  batch_norm_momentum: 0.02
  # Decide the mode of equivariance
  equivar_mode:
  # Dimension of the first feature maps
  first_features_dim: 128
  # Decide the mode of invariance
  invar_mode:
  label_to_names:
    0 : "unlabeled"
    1 : "outlier"
    10: "car"
    11: "bicycle"
    13: "bus"
    15: "motorcycle"
    16: "on-rails"
    18: "truck"
    20: "other-vehicle"
    30: "person"
    31: "bicyclist"
    32: "motorcyclist"
    40: "road"
    44: "parking"
    48: "sidewalk"
    49: "other-ground"
    50: "building"
    51: "fence"
    52: "other-structure"
    60: "lane-marking"
    70: "vegetation"
    71: "trunk"
    72: "terrain"
    80: "pole"
    81: "traffic-sign"
    99: "other-object"
    252: "moving-car"
    253: "moving-bicyclist"
    254: "moving-person"
    255: "moving-motorcyclist"
    256: "moving-on-rails"
    257: "moving-bus"
    258: "moving-truck"
    259: "moving-other-vehicle"
  num_layers:
  # Do we need to save convergence
  saving: True
  # For segmentation models: ratio between the segmented area and the input area
  segmentation_ratio:
  # Batch normalization parameters
  use_batch_norm: True

kpconv:
  # Aggregation function of KPConv in ('closest', 'sum')
  # Decide if you sum all kernel point influences,
  # or if you only take the influence of the closest KP
  aggregation_mode: sum
  # Radius of convolution in number grid cell. (2.5 is the standard value)
  conv_radius: 2.5
  # Deformable offset loss
  # Fitting geometry by penalizing distance from deform point to input points ('point2point')
  # or to input point triplet ('point2plane', not implemented)
  deform_fitting_mode: "point2point"
  # Multiplier for the fitting/repulsive loss
  deform_fitting_power: 1.0
  # Radius of deformable convolution in number grid cell. Larger so that deformed kernel can spread out
  deform_radius: 6.0
  # Size of the first subsampling grid in meters
  first_subsampling_dl: 0.06
  # Fixed points in the kernel : 'none', 'center' or 'verticals'
  fixed_kernel_points: none
  # Radius of the area of influence of each kernel point in number grid cell. (1.0 is the standard value)
  KP_extent: 1.2
  # Behaviour of convolutions. Influence function when d < KP_extent. ('constant', 'linear', 'gaussian')
  # When d > KP_extent, always zero
  KP_influence: linear
  # Maximal number of epochs
  max_epoch: 800
  max_in_points: 100000
  # Radius of the area of influence of each kernel point in number grid cell. (1.0 is the standard value)
  max_val_points: 100000
  # Can the network learn modulations (in deformable convolutions)
  modulated: False
  n_frames: 1
  num_kernel_points: 15
  val_radius: 51.0

train:
  # Augmentation parameters
  augment_color: 0.8
  augment_noise: 0.001
  augment_occlusion: none
  augment_occlusion_ratio: 0.2
  augment_occlusion_num: 1
  augment_rotation: vertical
  augment_scale_anisotropic: True
  augment_scale_min: 0.8
  augment_scale_max: 1.2
  augment_symmetries: [True, False, False]
  # Number of batch
  batch_num: 10
  # Frequency at which training checkpoints are saved on disk (in terms of epochs)
  checkpoint_gap: 50
  # Deformable offset loss
  # Fitting geometry by penalizing distance from deform point to input points ('point2point')
  # or to input point triplet ('point2plane', not implemented)
  # Choose weights for class (used in segmentation loss). Empty list for no weights
  # class proportion for R=10.0 and dl=0.08 (first is unlabeled)
  # 19.1 48.9 0.5 1.1 5.6 3.6 0.7 0.6 0.9 193.2 17.7 127.4 6.7 132.3 68.4 283.8 7.0 78.5 3.3 0.8
  # sqrt(Inverse of proportion * 100)
  # class_w = [1.430, 14.142, 9.535, 4.226, 5.270, 11.952, 12.910, 10.541, 0.719,
  #            2.377, 0.886, 3.863, 0.869, 1.209, 0.594, 3.780, 1.129, 5.505, 11.180]
  # sqrt(Inverse of proportion * 100)  capped (0.5 < X < 5)
  # class_w = [1.430, 5.000, 5.000, 4.226, 5.000, 5.000, 5.000, 5.000, 0.719, 2.377,
  #            0.886, 3.863, 0.869, 1.209, 0.594, 3.780, 1.129, 5.000, 5.000]
  class_w: {}
  # Multiplier for learning rate applied to the deformations
  deform_lr_factor: 0.1
  # Number of steps per epochs
  epoch_steps: 500
  # Gradient clipping value (negative means no clipping)
  grad_clip_norm: 100.0
  # Network optimizer parameters (learning rate and momentum)
  learning_rate: 0.01
  lr_decay_epochs:
  # Maximal number of epochs
  max_epoch:
  momentum: 0.98
  # Increment of inference potential before saving results
  potential_increment: 10
  # Distance of repulsion for deformed kernel points
  repulse_extent: 1.0
  # The way we balance segmentation loss
  #   'none': Each point in the whole batch has the same contribution.
  #   'class': Each class has the same contribution (points are weighted according to class balance)
  #   'batch': Each cloud in the batch has the same contribution (points are weighted according cloud sizes)
  segloss_balance: none
  val_batch_num: 8
  # Number of validation examples per epoch
  validation_size: 200
  # Regularization loss importance
  weight_decay: 0.001

test:
  # Increment of inference potential before saving results
  potential_increment: 10
  n_votes: 100
  val_bath_num: 10
  # Number of validation examples per epoch
  validation_size: 50

specific:
  color_map: { # bgr
    0 : [0, 0, 0],
    1 : [0, 0, 255],
    9: [75, 0, 175],
    10: [245, 150, 100],
    11: [245, 230, 100],
    13: [250, 80, 100],
    15: [150, 60, 30],
    16: [255, 0, 0],
    18: [180, 30, 80],
    20: [255, 0, 0],
    30: [30, 30, 255],
    31: [200, 40, 255],
    32: [90, 30, 150],
    40: [255, 0, 255],
    44: [255, 150, 255],
    48: [75, 0, 75],
    50: [0, 200, 255],
    51: [50, 120, 255],
    52: [0, 150, 255],
    60: [170, 255, 150],
    70: [0, 175, 0],
    71: [0, 60, 135],
    72: [80, 240, 150],
    80: [150, 240, 255],
    81: [0, 0, 255],
    99: [255, 255, 50],
    252: [245, 150, 100],
    256: [255, 0, 0],
    253: [200, 40, 255],
    254: [30, 30, 255],
    255: [90, 30, 150],
    257: [250, 80, 100],
    258: [180, 30, 80],
    259: [255, 0, 0]
  }

  # as a ratio with the total number of points
  content: {
    0: 0.018889854628292943,
    1: 0.0002937197336781505,
    10: 0.040818519255974316,
    11: 0.00016609538710764618,
    13: 2.7879693665067774e-05,
    15: 0.00039838616015114444,
    16: 0.0,
    18: 0.0020633612104619787,
    20: 0.0016218197275284021,
    30: 0.00017698551338515307,
    31: 1.1065903904919655e-08,
    32: 5.532951952459828e-09,
    40: 0.1987493871255525,
    44: 0.014717169549888214,
    48: 0.14392298360372,
    49: 0.0039048553037472045,
    50: 0.1326861944777486,
    51: 0.0723592229456223,
    52: 0.002395131480328884,
    60: 4.7084144280367186e-05,
    70: 0.26681502148037506,
    71: 0.006035012012626033,
    72: 0.07814222006271769,
    80: 0.002855498193863172,
    81: 0.0006155958086189918,
    99: 0.009923127583046915,
    252: 0.001789309418528068,
    253: 0.00012709999297008662,
    254: 0.00016059776092534436,
    255: 3.745553104802113e-05,
    256: 0.0,
    257: 0.00011351574470342043,
    258: 0.00010157861367183268,
    259: 4.3840131989471124e-05,
  }

  # classes that are indistinguishable from single scan or inconsistent in
  # ground truth are mapped to their closest equivalent
  learning_map: {
    0: 0,     # "unlabeled"
    1: 0,     # "outlier" mapped to "unlabeled" --------------------------mapped
    10: 1,     # "car"
    11: 2,     # "bicycle"
    13: 5,     # "bus" mapped to "other-vehicle" --------------------------mapped
    15: 3,     # "motorcycle"
    16: 5,     # "on-rails" mapped to "other-vehicle" ---------------------mapped
    18: 4,    # "truck"
    20: 5,    # "other-vehicle"
    30: 6,     # "person"
    31: 7,     # "bicyclist"
    32: 8,     # "motorcyclist"
    40: 9,     # "road"
    44: 10,    # "parking"
    48: 11,    # "sidewalk"
    49: 12,    # "other-ground"
    50: 13,    # "building"
    51: 14,    # "fence"
    52: 0,     # "other-structure" mapped to "unlabeled" ------------------mapped
    60: 9,     # "lane-marking" to "road" ---------------------------------mapped
    70: 15,    # "vegetation"
    71: 16,    # "trunk"
    72: 17,    # "terrain"
    80: 18,    # "pole"
    81: 19,    # "traffic-sign"
    99: 0,     # "other-object" to "unlabeled" ----------------------------mapped
    252: 20,   # "moving-car", can be 1
    253: 21,   # "moving-bicyclist", can be 7
    254: 22,   # "moving-person", can be 6
    255: 23,   # "moving-motorcyclist", can be 8
    256: 24,   # "moving-on-rails" mapped to "moving-other-vehicle", can be 5 ------mapped
    257: 24,   # "moving-bus" mapped to "moving-other-vehicle" can be 5 -----------mapped
    258: 25,   # "moving-truck", can be 4
    259: 24   # "moving-other-vehicle", can be 5
  }

  # inverse of previous map
  learning_map_inv: {
    0: 0,      # "unlabeled", and others ignored
    1: 10,     # "car"
    2: 11,     # "bicycle"
    3: 15,     # "motorcycle"
    4: 18,     # "truck"
    5: 20,     # "other-vehicle"
    6: 30,     # "person"
    7: 31,     # "bicyclist"
    8: 32,     # "motorcyclist"
    9: 40,     # "road"
    10: 44,    # "parking"
    11: 48,    # "sidewalk"
    12: 49,    # "other-ground"
    13: 50,    # "building"
    14: 51,    # "fence"
    15: 70,    # "vegetation"
    16: 71,    # "trunk"
    17: 72,    # "terrain"
    18: 80,    # "pole"
    19: 81,    # "traffic-sign"
    20: 252,    # "moving-car", optional
    21: 253,    # "moving-bicyclist", optional
    22: 254,    # "moving-person", optional
    23: 255,    # "moving-motorcyclist", optional
    24: 259,    # "moving-other-vehicle", optional
    25: 258    # "moving-truck", optional
  }

  # Ignore classes
  learning_ignore: {
    0: True,      # "unlabeled", and others ignored
    1: False,     # "car"
    2: False,     # "bicycle"
    3: False,     # "motorcycle"
    4: False,     # "truck"
    5: False,     # "other-vehicle"
    6: False,     # "person"
    7: False,     # "bicyclist"
    8: False,     # "motorcyclist"
    9: False,     # "road"
    10: False,    # "parking"
    11: False,    # "sidewalk"
    12: False,    # "other-ground"
    13: False,    # "building"
    14: False,    # "fence"
    15: False,    # "vegetation"
    16: False,    # "trunk"
    17: False,    # "terrain"
    18: False,   # "pole"
    19: False,    # "traffic-sign"
    20: False,    # "moving-car", optional
    21: False,    # "moving-bicyclist", optional
    22: False,    # "moving-person", optional
    23: False,    # "moving-motorcyclist", optional
    24: False,    # "moving-other-vehicle", optional
    25: False    # "moving-truck", optional
  }

  task: # sequence numbers
    train:
      - 0
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
      - 7
      - 9
      - 10
    validate: 8
    test:
      - 11
      - 12
      - 13
      - 14
      - 15
      - 16
      - 17
      - 18
      - 19
      - 20
      - 21
